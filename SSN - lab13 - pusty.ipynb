{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sztuczne sieci neuronowe - laboratorium 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Przygotowanie danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./data\\FashionMNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26421880/26421880 [00:12<00:00, 2174005.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\FashionMNIST\\raw\\train-images-idx3-ubyte.gz to ./data\\FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./data\\FashionMNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29515/29515 [00:00<00:00, 922280.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\FashionMNIST\\raw\\train-labels-idx1-ubyte.gz to ./data\\FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./data\\FashionMNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4422102/4422102 [00:02<00:00, 1851601.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\FashionMNIST\\raw\\t10k-images-idx3-ubyte.gz to ./data\\FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./data\\FashionMNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5148/5148 [00:00<00:00, 2572346.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\FashionMNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./data\\FashionMNIST\\raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_dataset = torchvision.datasets.FashionMNIST('./data',\n",
    "    download=True,\n",
    "    train=True,\n",
    "    transform=transform)\n",
    "\n",
    "val_dataset = torchvision.datasets.FashionMNIST('./data',\n",
    "    download=True,\n",
    "    train=False,\n",
    "    transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=4, shuffle=True, num_workers=2)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=4, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ćwiczenie\n",
    "Uruchom poniższą funkcję, aby zwizualizować przykładowe obrazki ze zbioru FashionMNIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matplotlib_imshow(img, one_channel=False):\n",
    "    if one_channel:\n",
    "        img = img.mean(dim=0)\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    if one_channel:\n",
    "        plt.imshow(npimg, cmap=\"Greys\")\n",
    "    else:\n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "matplotlib_imshow(train_dataset[22][0], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definicja modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(F.relu(self.conv1(x)))\n",
    "        x = self.pool2(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net()\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorboard\n",
    "\n",
    "Tensorboard w PyTorchu używa się z wykorzystaniem klasy `SummaryWriter`.  \n",
    "Potrzebny jest katalog, w którym będą zapisywane logi (domyslnie \"runs\").\n",
    "W momencie uruchomienia odpowiedniej metody do pliku z logami zapisywane są odpowiednie elementy.\n",
    "\n",
    "Tensorboard uruchamia się z poziomu konsoli: `tensorboard --logdir=ŚCIEŻKA_DO_KATALOGU` i działa się w przeglądarce (domyślnie port 6006).\n",
    "\n",
    "https://pytorch.org/docs/stable/tensorboard.html#torch.utils.tensorboard.writer.SummaryWriter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ćwiczenie\n",
    "\n",
    "Stwórz `SummaryWriter` i zapisz do pliku z logami cztery obrazki ze zbioru uczącego (`img_grid` poniżej)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter()\n",
    "\n",
    "images, labels = next(iter(train_loader))\n",
    "img_grid = torchvision.utils.make_grid(images)\n",
    "\n",
    "writer.add_image('images', img_grid)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ćwiczenie\n",
    "\n",
    "W Tensorboard można tez wizualizować modele. Wykorzystaj do tego metodę `add_graph`. Jako drugi argument podaj `images`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter()\n",
    "images, labels = next(iter(train_loader))\n",
    "img_grid = torchvision.utils.make_grid(images)\n",
    "writer.add_image('images', img_grid)\n",
    "writer.add_graph(model, images)\n",
    "writer.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorboard w trakcie treningu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions\n",
    "classes = train_dataset.classes\n",
    "\n",
    "def images_to_probs(net, images):\n",
    "    '''\n",
    "    Generates predictions and corresponding probabilities from a trained\n",
    "    network and a list of images\n",
    "    '''\n",
    "    output = net(images)\n",
    "    # convert output probabilities to predicted class\n",
    "    _, preds_tensor = torch.max(output, 1)\n",
    "    preds = np.squeeze(preds_tensor.numpy())\n",
    "    return preds, [F.softmax(el, dim=0)[i].item() for i, el in zip(preds, output)]\n",
    "\n",
    "\n",
    "def plot_classes_preds(net, images, labels):\n",
    "    '''\n",
    "    Generates matplotlib Figure using a trained network, along with images\n",
    "    and labels from a batch, that shows the network's top prediction along\n",
    "    with its probability, alongside the actual label, coloring this\n",
    "    information based on whether the prediction was correct or not.\n",
    "    Uses the \"images_to_probs\" function.\n",
    "    '''\n",
    "    preds, probs = images_to_probs(net, images)\n",
    "    # plot the images in the batch, along with predicted and true labels\n",
    "    fig = plt.figure(figsize=(12, 48))\n",
    "    for idx in np.arange(4):\n",
    "        ax = fig.add_subplot(1, 4, idx+1, xticks=[], yticks=[])\n",
    "        matplotlib_imshow(images[idx], one_channel=True)\n",
    "        ax.set_title(\"{0}, {1:.1f}%\\n(label: {2})\".format(\n",
    "            classes[preds[idx]],\n",
    "            probs[idx] * 100.0,\n",
    "            classes[labels[idx]]),\n",
    "                    color=(\"green\" if preds[idx]==labels[idx].item() else \"red\"))\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ćwiczenie\n",
    "Uzupełnij poniższy kod, aby co 1000 iteracji zapisać wartość funkcji straty oraz zwizualizować predykcje dla aktualnego batcha (użyj `plot_classes_preds`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1000\n",
      "Iteration 2000\n",
      "Iteration 3000\n",
      "Iteration 4000\n",
      "Iteration 5000\n",
      "Iteration 6000\n",
      "Iteration 7000\n",
      "Iteration 8000\n",
      "Iteration 9000\n",
      "Iteration 10000\n",
      "Iteration 11000\n",
      "Iteration 12000\n",
      "Iteration 13000\n",
      "Iteration 14000\n",
      "Iteration 15000\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "writer = SummaryWriter()\n",
    "running_loss = 0.0\n",
    "for i, data in enumerate(train_loader):\n",
    "\n",
    "    # get the inputs; data is a list of [inputs, labels]\n",
    "    inputs, labels = data\n",
    "\n",
    "    # zero the parameter gradients\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # forward + backward + optimize\n",
    "    outputs = model(inputs)\n",
    "    loss = loss_fn(outputs, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    running_loss += loss.item()\n",
    "    if i % 1000 == 999:    # every 1000 mini-batches...\n",
    "        print(f\"Iteration {i+1}\")\n",
    "\n",
    "        # ...log the running loss\n",
    "        # TU WPISZ KOD\n",
    "        writer.add_scalar('training loss',\n",
    "                            running_loss / 1000,\n",
    "                            i+1)\n",
    "        # ...log a Matplotlib Figure showing the model's predictions on a\n",
    "        # random mini-batch\n",
    "        # TU WPISZ KOD\n",
    "        writer.add_figure('predictions vs. actuals',\n",
    "                            plot_classes_preds(model, inputs, labels),\n",
    "                            global_step=i+1)\n",
    "                            \n",
    "        running_loss = 0.0\n",
    "print('Finished Training')\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ćwiczenie\n",
    "Zwizualizuj w Tensorboard krzywą precision-recall na zbiorze walidacyjnym (dla wytrenowanego modelu).  \n",
    "(na podstawie https://pytorch.org/tutorials/intermediate/tensorboard_tutorial.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. gets the probability predictions in a test_size x num_classes Tensor\n",
    "# 2. gets the preds in a test_size Tensor\n",
    "# takes ~10 seconds to run\n",
    "class_probs = []\n",
    "class_label = []\n",
    "with torch.no_grad():\n",
    "    for data in val_loader:\n",
    "        images, labels = data\n",
    "        output = model(images)\n",
    "        class_probs_batch = [F.softmax(el, dim=0) for el in output]\n",
    "\n",
    "        class_probs.append(class_probs_batch)\n",
    "        class_label.append(labels)\n",
    "\n",
    "test_probs = torch.cat([torch.stack(batch) for batch in class_probs])\n",
    "test_label = torch.cat(class_label)\n",
    "\n",
    "# helper function\n",
    "def add_pr_curve_tensorboard(class_index, test_probs, test_label, global_step=0):\n",
    "    '''\n",
    "    Takes in a \"class_index\" from 0 to 9 and plots the corresponding\n",
    "    precision-recall curve\n",
    "    '''\n",
    "    tensorboard_truth = test_label == class_index\n",
    "    tensorboard_probs = test_probs[:, class_index]\n",
    "    \n",
    "    writer = SummaryWriter()\n",
    "    writer.add_pr_curve(classes[class_index],\n",
    "                        tensorboard_truth,\n",
    "                        tensorboard_probs,\n",
    "                        global_step=global_step)\n",
    "    writer.close()\n",
    "\n",
    "# plot all the pr curves\n",
    "for i in range(len(classes)):\n",
    "    add_pr_curve_tensorboard(i, test_probs, test_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Zadanie domowe\n",
    "\n",
    "Wkomponiuj Tensorboard (`SummaryWriter`) w inny kod, np. z poprzednich ćwiczeń / wykładu / projektu. Wyślij prowadzącemu screenshot jako dowód wykonania zadania."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
